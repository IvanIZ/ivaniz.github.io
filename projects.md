---
layout: post_index
categories: media
title: ""

---

# Projects
This page shows my unpublished (but fun!) projects. For published research projects, please see my [publication page](https://scholar.google.ca/citations?user=8zyHdjoAAAAJ&hl=en&oi=ao).


<h2 style="margin-bottom: 0;">Context-Aware Human-Pet-Robot Interactions</h2>
<span style="color: blue; font-size: 14px;">\#Human-Robot Interactions</span>; <span style="color: blue; font-size: 14px;">\#Human Intent Predictions</span>
<img style="float: right; padding-left:20px;" src="/assets/hardware_figure.jpg" width="200" height="100">

Pet ownership is on the rise, yet the time and financial commitments it demands can deter many potential pet owners. Nonetheless, robotic pets have recently emerged as an appealing alternative. The foundation of a rewarding pet experience is rooted in human-pet interactions and the pets' ability to perceive the context of interactions. In this work, a context-aware human-pet-robot interaction system is developed. In particular, multi-modal sensor data, including audio and vision, are used to extract multi-channel context cues, such as the owner's posture, gesture, and audio keywords. A rule-based model is proposed to fuse the detected context signals and estimate the appropriate interaction context, such as engagement or following, and the pet robot behaves accordingly. The context detection model is evaluated in a sequence of human-robot interactions and promising evaluation results are reported. 

[[Report](https://ivaniz.github.io/Context_aware_HRI_Report.pdf)] [[Demo Video](https://drive.google.com/file/d/1FZqU1ECDhD2d93hmC90mmE7PjuCymzC-/view?usp=sharing)]

## SLAM-based Attentiveness Map Estimation

* page content under construction...Coming soon!

